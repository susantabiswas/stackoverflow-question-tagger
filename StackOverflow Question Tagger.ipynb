{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>StackOverflow Tag Predictor\n",
    "StackOverflow lets us post your queries and the other user can help you with answers. The site uses tags for managing the questions effectively. Here we will be predicting tags for a given question. Tags like C, C++, Python are widely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading the data\n",
    "def load_data(dirname):\n",
    "    # laod the data file\n",
    "    data = pd.read_csv(dirname, sep='\\t')\n",
    "    # convert string charcter to language syntactic characters if any\n",
    "    data['tags'] = data['tags'].apply(literal_eval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation data\n",
    "train_data = load_data('dataset/train.tsv')\n",
    "val_data = load_data('dataset/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data = pd.read_csv('dataset/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>[php, mysql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                  tags\n",
       "0                How to draw a stacked dotplot in R?                   [r]\n",
       "1  mysql select all records where a datetime fiel...          [php, mysql]\n",
       "2             How to terminate windows phone 8.1 app                  [c#]\n",
       "3  get current time in a specific country via jquery  [javascript, jquery]\n",
       "4                      Configuring Tomcat to Use SSL                [java]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "X_train = train_data['title'].values \n",
    "y_train = train_data['tags'].values\n",
    "# validation data\n",
    "X_val = val_data['title'].values\n",
    "y_val = val_data['tags'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,)\n",
      "(100000,)\n",
      "(30000,)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Text Preprocessing\n",
    "We remove the punctuations, unecessary whitespaces and some other characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess text\n",
    "def preprocess_data(text):\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # replace whitespaces and punctuations\n",
    "    text = re.sub('[/(){}\\[\\]\\|@,;]', ' ', text)\n",
    "    text = re.sub('[^0-9a-z #+_]', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "X_train = [preprocess_data(text) for text in X_train]\n",
    "X_val = [preprocess_data(text) for text in X_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find word and tag frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequency(X_train, y_train):\n",
    "    # dictionary of all tags with their frequency.\n",
    "    tag_counts = defaultdict(int)\n",
    "    # dictionary of all words with their frequency.\n",
    "    word_counts = defaultdict(int)\n",
    "\n",
    "    # find tag counts\n",
    "    for _,tags in tqdm(enumerate(y_train)):\n",
    "        for tag in tags:\n",
    "            #print(tag)\n",
    "            tag_counts[tag] += 1\n",
    "\n",
    "    # for words\n",
    "    for _,senten in tqdm(enumerate(X_train)):\n",
    "        for word in senten.split():\n",
    "            word_counts[word] += 1\n",
    "    \n",
    "    return word_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000it [00:00, 1279796.91it/s]\n",
      "100000it [00:00, 399972.54it/s]\n"
     ]
    }
   ],
   "source": [
    "word_counts, tag_counts = compute_frequency(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create vocabulary dictionary of top **N** words from the training data. We need two mappings:<br>\n",
    "1) Words to index<br>\n",
    "2) Index to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for creating word to index and vice versa mappings\n",
    "def create_vocabulary_mappings(X_train, word_counts, DICT_SIZE=4500):\n",
    "    # word to index mapping\n",
    "    word_to_idx = {word:idx for idx,(word,f) in enumerate(\n",
    "                sorted(word_counts.items(), key=lambda v:v[1], reverse=True)[:DICT_SIZE])}\n",
    "    # reverse index to word mapping\n",
    "    idx_to_word= {word_to_idx[word]:word for word in word_to_idx.keys()}\n",
    "    \n",
    "    return word_to_idx, idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE=4500\n",
    "word_to_idx, idx_to_word = create_vocabulary_mappings(X_train, word_counts, DICT_SIZE=4500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be trying two feature representations : Bag of Words(BOW) and TF-IDF. First we will create a function for **BOW**. For BOW we will use most commonly used 4500 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for creating BOW representation\n",
    "def create_bag_of_words(text, word_to_idx, DICT_SIZE):\n",
    "    # Intial Matrix for holding the features\n",
    "    feature_vector = np.zeros(DICT_SIZE)\n",
    "    \n",
    "    # update the word frequencies\n",
    "    for word in text.split():\n",
    "        if word in word_to_idx.keys():\n",
    "            feature_vector[word_to_idx[word]] += 1 \n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (100000, 4500)\n",
      "X_val shape  (30000, 4500)\n"
     ]
    }
   ],
   "source": [
    "# create the bag of words feature vector\n",
    "# we will use a sparse representation , here we will be using csr matrix representation\n",
    "# for storing it\n",
    "X_train_bow = sparse.vstack([sparse.csr_matrix(create_bag_of_words(text, word_to_idx, DICT_SIZE)) for text in X_train])\n",
    "X_val_bow = sparse.vstack([sparse.csr_matrix(create_bag_of_words(text, word_to_idx, DICT_SIZE)) for text in X_val])\n",
    "\n",
    "print('X_train shape ', X_train_bow.shape)\n",
    "print('X_val shape ', X_val_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates tf-idf feature vector\n",
    "def create_tfidf_features(X_train, X_val):\n",
    "    # fit for training data\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')####### YOUR CODE HERE #######\n",
    "    # apply for training and validation set\n",
    "    X_train = tfidf.fit_transform(X_train)\n",
    "    X_val = tfidf.transform(X_val)\n",
    "    \n",
    "    return X_train, X_val, tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, tfidf_vocab = create_tfidf_features(X_train, X_val)\n",
    "tfidf_reverse_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
